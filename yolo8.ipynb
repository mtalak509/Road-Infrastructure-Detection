{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ad02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f7b700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafc69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/home/maxim/DS/ds-phase-2/cv_project/yolo8m_model/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82ab3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–∏: {0: 'Speedlimit', 1: 'Stopsign', 2: 'Trafficlight'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"–ö–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–∏: {model.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f1f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# –ï—Å–ª–∏ model.names —É–∂–µ —Å–ª–æ–≤–∞—Ä—å {id: name}\n",
    "model_classes = model.names\n",
    "\n",
    "data = {\n",
    "    \"classes\": model_classes\n",
    "}\n",
    "\n",
    "with open('model_classes.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7854f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Segmentation-Speedlimit-2 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12890/12890 [00:01<00:00, 8463.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Segmentation-Speedlimit-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 488/488 [00:00<00:00, 5320.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"sclPIxmqfKhFNRaI78wp\")\n",
    "project = rf.workspace(\"project-a0jvt\").project(\"segmentation-speedlimit-gqsun\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e85f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/maxim/DS/ds-phase-2/cv_project/Initial dataset/images/road22.png: 640x544 1 Stopsign, 581.3ms\n",
      "Speed: 8.1ms preprocess, 581.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Results saved to \u001b[1m/home/maxim/DS/ds-phase-2/cv_project/yolo8m_model/results/experiment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(\n",
    "    source='/home/maxim/DS/ds-phase-2/cv_project/Initial dataset/images/road22.png',\n",
    "    save=True,\n",
    "    show=False, \n",
    "    project='/home/maxim/DS/ds-phase-2/cv_project/yolo8m_model/results',  # –æ—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞\n",
    "    name='experiment',           # –ø–æ–¥–ø–∞–ø–∫–∞\n",
    "    exist_ok=True                  # –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df4eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è 'save_hybrid' is deprecated and will be removed in the future.\n",
      "Ultralytics 8.3.221 üöÄ Python-3.12.11 torch-2.9.0+cu128 CPU (Intel Core i5-1035G1 1.00GHz)\n",
      "YOLOv8m-seg summary (fused): 105 layers, 27,224,121 parameters, 0 gradients, 104.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 102.0¬±27.4 MB/s, size: 40.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/maxim/DS/ds-phase-2/cv_project/Train dataset/test/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 60/60 139.7Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 0.1it/s 1:07<27.8s\n",
      "                   all         60         68      0.981      0.987      0.992       0.93      0.981      0.987      0.992      0.878\n",
      "            Speedlimit         35         38          1      0.974      0.986      0.892          1      0.974      0.986      0.821\n",
      "              Stopsign         13         13      0.943          1      0.995      0.976      0.943          1      0.995      0.937\n",
      "          Trafficlight         12         17          1      0.986      0.995      0.923          1      0.986      0.995      0.876\n",
      "Speed: 3.6ms preprocess, 1067.7ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Saving /home/maxim/DS/ds-phase-2/runs/segment/val3/predictions.json...\n",
      "Results saved to \u001b[1m/home/maxim/DS/ds-phase-2/runs/segment/val3\u001b[0m\n",
      "‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(\n",
    "    data='../../datasets/Ships',  # –≤–∞—à data.yaml —Ñ–∞–π–ª\n",
    "    split='test',                     # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä\n",
    "    batch=16,                        # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n",
    "    imgsz=640,                       # —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    conf=0.1,                      # –ø–æ—Ä–æ–≥ confidence –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏\n",
    "    iou=0.6,                         # –ø–æ—Ä–æ–≥ IoU\n",
    "    device=DEVICE,                   # –∏–ª–∏ 'cpu'\n",
    "    save_json=True,                  # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON\n",
    "    save_hybrid=True,                # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    plots=True                       # –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏\n",
    ")\n",
    "\n",
    "print(\"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436610d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/maxim/DS/projects/Road-Infrastructure-Detection/Train dataset/valid/images/road346_png.rf.f13f89c3bf845d025b8835d6c8315f5a.jpg: 640x640 1 Speedlimit, 822.5ms\n",
      "Speed: 11.3ms preprocess, 822.5ms inference, 15.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"Train dataset/valid/images/road346_png.rf.f13f89c3bf845d025b8835d6c8315f5a.jpg\")  # predict on an image\n",
    "\n",
    "# Access the results\n",
    "for result in results:\n",
    "    xy = result.masks.xy  # mask in polygon format\n",
    "    xyn = result.masks.xyn  # normalized\n",
    "    masks = result.masks.data  # mask in matrix format (num_objects x H x W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc97c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–µ—Ç–µ–∫—Ü–∏–∏:\n",
      "–û–±—ä–µ–∫—Ç 1: Speedlimit (–∫–ª–∞—Å—Å 0), —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 0.95\n"
     ]
    }
   ],
   "source": [
    "result = results[0]\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–æ–º\n",
    "boxes = result.boxes\n",
    "\n",
    "# –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∞—Å—Å—ã, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã\n",
    "class_indices = boxes.cls.int().tolist()\n",
    "confidences = boxes.conf.tolist()\n",
    "class_names = [model.names[i] for i in class_indices]\n",
    "\n",
    "print(\"–î–µ—Ç–µ–∫—Ü–∏–∏:\")\n",
    "for i, (class_idx, class_name, conf) in enumerate(zip(class_indices, class_names, confidences)):\n",
    "    print(f\"–û–±—ä–µ–∫—Ç {i+1}: {class_name} (–∫–ª–∞—Å—Å {class_idx}), —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39de5b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Masks object with attributes:\n",
       "\n",
       "data: tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n",
       "orig_shape: (640, 640)\n",
       "shape: torch.Size([1, 640, 640])\n",
       "xy: [array([[182., 326.],\n",
       "       [182., 437.],\n",
       "       [329., 437.],\n",
       "       [329., 326.]], dtype=float32)]\n",
       "xyn: [array([[0.284375 , 0.509375 ],\n",
       "       [0.284375 , 0.6828125],\n",
       "       [0.5140625, 0.6828125],\n",
       "       [0.5140625, 0.509375 ]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1fb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Phase2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
